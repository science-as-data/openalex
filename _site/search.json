[
  {
    "objectID": "examples/exploring-subfields.html",
    "href": "examples/exploring-subfields.html",
    "title": "Exploring Research Subfields with the OpenAlex API",
    "section": "",
    "text": "We start by defining the fields we want to explore and two helper functions. FIELDS maps each field name to its OpenAlex identifier. get_subfields() queries the /subfields endpoint for a given field and returns the results as a DataFrame with columns for the field name, subfield name, and work count. plot_subfields() renders a horizontal bar chart from that DataFrame.\n\n\nCode\nimport os\nimport time\nimport httpx\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nBASE_URL = \"https://api.openalex.org\"\n\napi = httpx.Client(\n    base_url=BASE_URL,\n    params={\n        \"mailto\": os.environ.get(\"OPENALEX_MAILTO\", \"\"),\n        \"api_key\": os.environ[\"OPENALEX_API_KEY\"],\n    },\n    timeout=30,\n)\n\nFIELDS = {\n    \"Physics and Astronomy\": \"fields/31\",\n    \"Agricultural and Biological Sciences\": \"fields/11\",\n    \"Biochemistry, Genetics and Molecular Biology\": \"fields/13\",\n    \"Economics, Econometrics and Finance\": \"fields/20\",\n}\n\n\ndef _get(path: str, **kwargs) -&gt; dict:\n    \"\"\"GET with automatic retry on 429 and connection errors.\"\"\"\n    for attempt in range(5):\n        try:\n            r = api.get(path, **kwargs)\n        except httpx.ReadError:\n            time.sleep(2 ** attempt)\n            continue\n        if r.status_code == 429:\n            time.sleep(2 ** attempt)\n            continue\n        r.raise_for_status()\n        return r.json()\n    raise RuntimeError(\"Max retries exceeded\")\n\n\ndef get_subfields(field_name: str, field_id: str) -&gt; pd.DataFrame:\n    data = _get(\"/subfields\", params={\n        \"filter\": f\"field.id:{field_id}\",\n        \"select\": \"id,display_name,works_count\",\n        \"per-page\": 50,\n        \"sort\": \"works_count:desc\",\n    })\n    df = pd.DataFrame(data[\"results\"])[[\"display_name\", \"works_count\"]]\n    df.columns = [\"Subfield\", \"Works\"]\n    df.insert(0, \"Field\", field_name)\n    return df\n\n\nBAR_HEIGHT = 0.25  # inches per bar — keeps bars the same size across charts\n\n\ndef plot_subfields(df: pd.DataFrame):\n    fig_h = max(2, len(df) * BAR_HEIGHT + 1)\n    fig, ax = plt.subplots(figsize=(6, fig_h))\n    ax.barh(df[\"Subfield\"][::-1], df[\"Works\"][::-1], color=\"#9e9e9e\")\n    ax.set_xlabel(\"Number of works\")\n    ax.grid(axis=\"x\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()\n\n\ndef get_works_by_year(field_name: str, field_id: str) -&gt; pd.DataFrame:\n    data = _get(\"/works\", params={\n        \"filter\": f\"primary_topic.field.id:{field_id}\",\n        \"group_by\": \"publication_year\",\n    })\n    rows = [\n        {\"Year\": int(g[\"key\"]), \"Works\": g[\"count\"]}\n        for g in data[\"group_by\"]\n        if g[\"key\"] != \"unknown\"\n    ]\n    df = pd.DataFrame(rows).sort_values(\"Year\")\n    df.insert(0, \"Field\", field_name)\n    return df\n\n\ndef plot_works_by_year(df: pd.DataFrame):\n    fig, ax = plt.subplots(figsize=(6, 3))\n    ax.fill_between(df[\"Year\"], df[\"Works\"], alpha=0.3, color=\"#e67e22\")\n    ax.plot(df[\"Year\"], df[\"Works\"], color=\"#e67e22\", linewidth=1.5)\n    ax.set_xlabel(\"Publication year\")\n    ax.set_ylabel(\"Number of works\")\n    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:,.0f}\"))\n    ax.grid(axis=\"y\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()\n\n\ndef get_works_by_source(field_name: str, field_id: str) -&gt; pd.DataFrame:\n    params = {\n        \"filter\": f\"primary_topic.field.id:{field_id}\",\n        \"group_by\": \"primary_location.source.id\",\n        \"per-page\": 200,\n        \"cursor\": \"*\",\n    }\n    rows = []\n    while True:\n        data = _get(\"/works\", params=params)\n        for g in data[\"group_by\"]:\n            rows.append({\"Source\": g[\"key_display_name\"], \"Works\": g[\"count\"]})\n        cursor = data[\"meta\"].get(\"next_cursor\")\n        if not cursor or len(data[\"group_by\"]) == 0:\n            break\n        params[\"cursor\"] = cursor\n        time.sleep(0.1)\n    df = pd.DataFrame(rows).sort_values(\"Works\", ascending=False).reset_index(drop=True)\n    df.insert(0, \"Field\", field_name)\n    return df\n\n\nTOP_N_SOURCES = 20\n\n\ndef plot_works_by_source(df: pd.DataFrame):\n    top = df.head(TOP_N_SOURCES)\n    fig_h = max(2, len(top) * BAR_HEIGHT + 1)\n    fig, ax = plt.subplots(figsize=(6, fig_h))\n    ax.barh(top[\"Source\"][::-1], top[\"Works\"][::-1], color=\"#2980b9\")\n    ax.set_xlabel(\"Number of works\")\n    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:,.0f}\"))\n    ax.grid(axis=\"x\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "examples/exploring-subfields.html#setup",
    "href": "examples/exploring-subfields.html#setup",
    "title": "Exploring Research Subfields with the OpenAlex API",
    "section": "",
    "text": "We start by defining the fields we want to explore and two helper functions. FIELDS maps each field name to its OpenAlex identifier. get_subfields() queries the /subfields endpoint for a given field and returns the results as a DataFrame with columns for the field name, subfield name, and work count. plot_subfields() renders a horizontal bar chart from that DataFrame.\n\n\nCode\nimport os\nimport time\nimport httpx\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nBASE_URL = \"https://api.openalex.org\"\n\napi = httpx.Client(\n    base_url=BASE_URL,\n    params={\n        \"mailto\": os.environ.get(\"OPENALEX_MAILTO\", \"\"),\n        \"api_key\": os.environ[\"OPENALEX_API_KEY\"],\n    },\n    timeout=30,\n)\n\nFIELDS = {\n    \"Physics and Astronomy\": \"fields/31\",\n    \"Agricultural and Biological Sciences\": \"fields/11\",\n    \"Biochemistry, Genetics and Molecular Biology\": \"fields/13\",\n    \"Economics, Econometrics and Finance\": \"fields/20\",\n}\n\n\ndef _get(path: str, **kwargs) -&gt; dict:\n    \"\"\"GET with automatic retry on 429 and connection errors.\"\"\"\n    for attempt in range(5):\n        try:\n            r = api.get(path, **kwargs)\n        except httpx.ReadError:\n            time.sleep(2 ** attempt)\n            continue\n        if r.status_code == 429:\n            time.sleep(2 ** attempt)\n            continue\n        r.raise_for_status()\n        return r.json()\n    raise RuntimeError(\"Max retries exceeded\")\n\n\ndef get_subfields(field_name: str, field_id: str) -&gt; pd.DataFrame:\n    data = _get(\"/subfields\", params={\n        \"filter\": f\"field.id:{field_id}\",\n        \"select\": \"id,display_name,works_count\",\n        \"per-page\": 50,\n        \"sort\": \"works_count:desc\",\n    })\n    df = pd.DataFrame(data[\"results\"])[[\"display_name\", \"works_count\"]]\n    df.columns = [\"Subfield\", \"Works\"]\n    df.insert(0, \"Field\", field_name)\n    return df\n\n\nBAR_HEIGHT = 0.25  # inches per bar — keeps bars the same size across charts\n\n\ndef plot_subfields(df: pd.DataFrame):\n    fig_h = max(2, len(df) * BAR_HEIGHT + 1)\n    fig, ax = plt.subplots(figsize=(6, fig_h))\n    ax.barh(df[\"Subfield\"][::-1], df[\"Works\"][::-1], color=\"#9e9e9e\")\n    ax.set_xlabel(\"Number of works\")\n    ax.grid(axis=\"x\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()\n\n\ndef get_works_by_year(field_name: str, field_id: str) -&gt; pd.DataFrame:\n    data = _get(\"/works\", params={\n        \"filter\": f\"primary_topic.field.id:{field_id}\",\n        \"group_by\": \"publication_year\",\n    })\n    rows = [\n        {\"Year\": int(g[\"key\"]), \"Works\": g[\"count\"]}\n        for g in data[\"group_by\"]\n        if g[\"key\"] != \"unknown\"\n    ]\n    df = pd.DataFrame(rows).sort_values(\"Year\")\n    df.insert(0, \"Field\", field_name)\n    return df\n\n\ndef plot_works_by_year(df: pd.DataFrame):\n    fig, ax = plt.subplots(figsize=(6, 3))\n    ax.fill_between(df[\"Year\"], df[\"Works\"], alpha=0.3, color=\"#e67e22\")\n    ax.plot(df[\"Year\"], df[\"Works\"], color=\"#e67e22\", linewidth=1.5)\n    ax.set_xlabel(\"Publication year\")\n    ax.set_ylabel(\"Number of works\")\n    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:,.0f}\"))\n    ax.grid(axis=\"y\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()\n\n\ndef get_works_by_source(field_name: str, field_id: str) -&gt; pd.DataFrame:\n    params = {\n        \"filter\": f\"primary_topic.field.id:{field_id}\",\n        \"group_by\": \"primary_location.source.id\",\n        \"per-page\": 200,\n        \"cursor\": \"*\",\n    }\n    rows = []\n    while True:\n        data = _get(\"/works\", params=params)\n        for g in data[\"group_by\"]:\n            rows.append({\"Source\": g[\"key_display_name\"], \"Works\": g[\"count\"]})\n        cursor = data[\"meta\"].get(\"next_cursor\")\n        if not cursor or len(data[\"group_by\"]) == 0:\n            break\n        params[\"cursor\"] = cursor\n        time.sleep(0.1)\n    df = pd.DataFrame(rows).sort_values(\"Works\", ascending=False).reset_index(drop=True)\n    df.insert(0, \"Field\", field_name)\n    return df\n\n\nTOP_N_SOURCES = 20\n\n\ndef plot_works_by_source(df: pd.DataFrame):\n    top = df.head(TOP_N_SOURCES)\n    fig_h = max(2, len(top) * BAR_HEIGHT + 1)\n    fig, ax = plt.subplots(figsize=(6, fig_h))\n    ax.barh(top[\"Source\"][::-1], top[\"Works\"][::-1], color=\"#2980b9\")\n    ax.set_xlabel(\"Number of works\")\n    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:,.0f}\"))\n    ax.grid(axis=\"x\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "examples/exploring-subfields.html#fetch-data",
    "href": "examples/exploring-subfields.html#fetch-data",
    "title": "Exploring Research Subfields with the OpenAlex API",
    "section": "Fetch data",
    "text": "Fetch data\nWe loop over the four fields and collect subfield breakdowns, yearly publication counts, and top sources for each one.\n\n\nCode\nfrom tqdm.auto import tqdm\n\ndfs = {}\nyearly = {}\nsources = {}\nfor name, fid in tqdm(FIELDS.items(), total=len(FIELDS), desc=\"Fields\"):\n    dfs[name] = get_subfields(name, fid)\n    yearly[name] = get_works_by_year(name, fid)\n    sources[name] = get_works_by_source(name, fid)"
  },
  {
    "objectID": "examples/exploring-subfields.html#save-to-csv",
    "href": "examples/exploring-subfields.html#save-to-csv",
    "title": "Exploring Research Subfields with the OpenAlex API",
    "section": "Save to CSV",
    "text": "Save to CSV\nPersists all three datasets to the data/ directory — one CSV per field plus a combined file for each dataset (subfields, works-by-year, works-by-source), giving 15 files in total. The combined files are what the Field-level analysis section reads back via pd.read_csv().\n\n\nCode\nfrom pathlib import Path\n\ndata_dir = Path(\"data\")\ndata_dir.mkdir(exist_ok=True)\n\nfor name, df in dfs.items():\n    slug = name.lower().replace(\", \", \"-\").replace(\" \", \"-\")\n    path = data_dir / f\"subfields-{slug}.csv\"\n    df.to_csv(path, index=False)\n    print(f\"Saved {len(df):&gt;2} rows to {path}\")\n\nall_subfields = pd.concat(dfs.values(), ignore_index=True)\npath = data_dir / \"subfields.csv\"\nall_subfields.to_csv(path, index=False)\nprint(f\"Saved {len(all_subfields):&gt;2} rows to {path} (combined)\")\n\nfor name, df in yearly.items():\n    slug = name.lower().replace(\", \", \"-\").replace(\" \", \"-\")\n    path = data_dir / f\"works-by-year-{slug}.csv\"\n    df.to_csv(path, index=False)\n    print(f\"Saved {len(df):&gt;2} rows to {path}\")\n\nall_yearly = pd.concat(yearly.values(), ignore_index=True)\npath = data_dir / \"works-by-year.csv\"\nall_yearly.to_csv(path, index=False)\nprint(f\"Saved {len(all_yearly):&gt;2} rows to {path} (combined)\")\n\nfor name, df in sources.items():\n    slug = name.lower().replace(\", \", \"-\").replace(\" \", \"-\")\n    path = data_dir / f\"works-by-source-{slug}.csv\"\n    df.to_csv(path, index=False)\n    print(f\"Saved {len(df):&gt;5,} rows to {path}\")\n\nall_sources = pd.concat(sources.values(), ignore_index=True)\npath = data_dir / \"works-by-source.csv\"\nall_sources.to_csv(path, index=False)\nprint(f\"Saved {len(all_sources):&gt;5,} rows to {path} (combined)\")"
  },
  {
    "objectID": "examples/exploring-subfields.html#field-level-analysis",
    "href": "examples/exploring-subfields.html#field-level-analysis",
    "title": "Exploring Research Subfields with the OpenAlex API",
    "section": "Field-level analysis",
    "text": "Field-level analysis\nThe visualisations below are driven by the CSV files saved in the previous steps. Re-run the Fetch data and Save to CSV cells when you need to refresh the underlying data.\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nall_subfields = pd.read_csv(\"data/subfields.csv\")\nall_yearly = pd.read_csv(\"data/works-by-year.csv\")\nall_sources = pd.read_csv(\"data/works-by-source.csv\")\n\ndfs = {name: g.reset_index(drop=True) for name, g in all_subfields.groupby(\"Field\")}\nyearly = {name: g.reset_index(drop=True) for name, g in all_yearly.groupby(\"Field\")}\nsources = {name: g.reset_index(drop=True) for name, g in all_sources.groupby(\"Field\")}\n\nBAR_HEIGHT = 0.25\n\n\ndef plot_subfields(df: pd.DataFrame):\n    fig_h = max(2, len(df) * BAR_HEIGHT + 1)\n    fig, ax = plt.subplots(figsize=(6, fig_h))\n    ax.barh(df[\"Subfield\"][::-1], df[\"Works\"][::-1], color=\"#9e9e9e\")\n    ax.set_xlabel(\"Number of works\")\n    ax.grid(axis=\"x\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_works_by_year(df: pd.DataFrame):\n    fig, ax = plt.subplots(figsize=(6, 3))\n    ax.fill_between(df[\"Year\"], df[\"Works\"], alpha=0.3, color=\"#e67e22\")\n    ax.plot(df[\"Year\"], df[\"Works\"], color=\"#e67e22\", linewidth=1.5)\n    ax.set_xlabel(\"Publication year\")\n    ax.set_ylabel(\"Number of works\")\n    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:,.0f}\"))\n    ax.grid(axis=\"y\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()\n\n\nTOP_N_SOURCES = 20\n\n\ndef plot_works_by_source(df: pd.DataFrame):\n    top = df.head(TOP_N_SOURCES)\n    fig_h = max(2, len(top) * BAR_HEIGHT + 1)\n    fig, ax = plt.subplots(figsize=(6, fig_h))\n    ax.barh(top[\"Source\"][::-1], top[\"Works\"][::-1], color=\"#2980b9\")\n    ax.set_xlabel(\"Number of works\")\n    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{x:,.0f}\"))\n    ax.grid(axis=\"x\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()\n\n\ndef table_top_sources(df: pd.DataFrame):\n    top = df.head(TOP_N_SOURCES)[[\"Source\", \"Works\"]].copy()\n    top.index = range(1, len(top) + 1)\n    top.index.name = \"Rank\"\n    top[\"Works\"] = top[\"Works\"].map(\"{:,}\".format)\n    print(top.to_markdown())\n\n\ndef plot_source_rank_freq(df: pd.DataFrame):\n    rank = range(1, len(df) + 1)\n    fig, ax = plt.subplots(figsize=(6, 3))\n    ax.scatter(rank, df[\"Works\"], s=12, alpha=0.4, facecolors=\"#8e44ad\", edgecolors=\"#8e44ad\", linewidths=0.5)\n    ax.set_xscale(\"log\")\n    ax.set_yscale(\"log\")\n    ax.set_xlabel(\"Source rank\")\n    ax.set_ylabel(\"Number of works\")\n    ax.grid(True, which=\"major\", color=\"#b0bec5\", linewidth=0.5, linestyle=\"--\")\n    ax.set_axisbelow(True)\n    for spine in ax.spines.values():\n        spine.set_visible(False)\n    plt.tight_layout()\n    plt.show()\n\n\n\nPhysics and Astronomy\n\nCode\ntotal = dfs[\"Physics and Astronomy\"][\"Works\"].sum()\nn_sources = len(sources[\"Physics and Astronomy\"])\nprint(f\"OpenAlex entity: [fields/31](https://openalex.org/fields/31) | {total:,} total works | {n_sources:,} unique journals | Subfields data: [CSV](data/subfields.csv)\")\n\nOpenAlex entity: fields/31 | 24,429,050 total works | 62,267 unique journals | Subfields data: CSV\n\n\nCode\nplot_works_by_year(yearly[\"Physics and Astronomy\"])\n\n\n\n\n\n\n\n\nFigure 1: Annual distribution of works in Physics and Astronomy.\n\n\n\n\n\n\nCode\ntable_top_sources(sources[\"Physics and Astronomy\"])\n\n\n\n\n\n\n\n\n\nRank\nSource\nWorks\n\n\n\n\n1\narXiv (Cornell University)\n409,029\n\n\n2\nThe Astrophysical Journal\n118,870\n\n\n3\nPhysical Review Letters\n94,100\n\n\n4\nZenodo (CERN European Organization for Nuclear Research)\n83,026\n\n\n5\nMonthly Notices of the Royal Astronomical Society\n80,450\n\n\n6\nOSTI OAI (U.S. Department of Energy Office of Scientific and Technical Information)\n79,307\n\n\n7\nBulletin of the American Physical Society\n68,927\n\n\n8\nProceedings of SPIE, the International Society for Optical Engineering/Proceedings of SPIE\n63,961\n\n\n9\nPhysics Letters B\n60,256\n\n\n10\nThe Journal of Chemical Physics\n59,294\n\n\n11\nPhysical review. B, Condensed matter\n58,862\n\n\n12\nAIP conference proceedings\n58,575\n\n\n13\nAstronomy and Astrophysics\n49,332\n\n\n14\nApplied Physics Letters\n43,785\n\n\n15\nJournal of Applied Physics\n43,460\n\n\n16\nJournal of High Energy Physics\n43,057\n\n\n17\nNature\n42,423\n\n\n18\nJournal of Physics Conference Series\n39,543\n\n\n19\nPhysical review. D. Particles, fields, gravitation, and cosmology/Physical review. D. Particles and fields\n39,263\n\n\n20\nPhysical review. D/Physical review. D.\n38,847\n\n\n\n\n\nCode\nplot_source_rank_freq(sources[\"Physics and Astronomy\"])\n\n\n\n\n\n\n\n\nFigure 2: Rank–frequency distribution of sources in Physics and Astronomy (log–log).\n\n\n\n\n\n\n\nCode\nplot_subfields(dfs[\"Physics and Astronomy\"])\n\n\n\n\n\n\n\n\nFigure 3: Subfields of Physics and Astronomy ranked by number of works.\n\n\n\n\n\n\n\nAgricultural and Biological Sciences\n\nCode\ntotal = dfs[\"Agricultural and Biological Sciences\"][\"Works\"].sum()\nn_sources = len(sources[\"Agricultural and Biological Sciences\"])\nprint(f\"OpenAlex entity: [fields/11](https://openalex.org/fields/11) | {total:,} total works | {n_sources:,} unique journals | Subfields data: [CSV](data/subfields.csv)\")\n\nOpenAlex entity: fields/11 | 21,496,854 total works | 131,819 unique journals | Subfields data: CSV\n\n\nCode\nplot_works_by_year(yearly[\"Agricultural and Biological Sciences\"])\n\n\n\n\n\n\n\n\nFigure 4: Annual distribution of works in Agricultural and Biological Sciences.\n\n\n\n\n\n\nCode\ntable_top_sources(sources[\"Agricultural and Biological Sciences\"])\n\n\n\n\n\n\n\n\n\nRank\nSource\nWorks\n\n\n\n\n1\nPubMed\n185,410\n\n\n2\nIUCN Red List of Threatened Species\n141,396\n\n\n3\nHAL (Le Centre pour la Communication Scientifique Directe)\n111,827\n\n\n4\nZenodo (CERN European Organization for Nuclear Research)\n95,049\n\n\n5\nSHILAP Revista de lepidopterología\n81,333\n\n\n6\nLA Referencia (Red Federada de Repositorios Institucionales de Publicaciones Científicas)\n78,899\n\n\n7\nFigshare\n71,481\n\n\n8\nActa Horticulturae\n55,800\n\n\n9\nMedical Entomology and Zoology\n46,690\n\n\n10\nDialnet (Universidad de la Rioja)\n46,034\n\n\n11\nAgritrop (Cirad)\n43,254\n\n\n12\nSSRN Electronic Journal\n42,855\n\n\n13\nElsevier eBooks\n40,407\n\n\n14\nBiodiversity Heritage Library (Smithsonian Institution)\n40,194\n\n\n15\nThe NamesforLife Abstracts\n37,663\n\n\n16\nRePEc: Research Papers in Economics\n36,190\n\n\n17\nAmericanae (AECID Library)\n31,722\n\n\n18\nNature\n28,615\n\n\n19\nJournal of Animal Science\n25,836\n\n\n20\nJournal of Economic Entomology\n25,541\n\n\n\n\n\nCode\nplot_source_rank_freq(sources[\"Agricultural and Biological Sciences\"])\n\n\n\n\n\n\n\n\nFigure 5: Rank–frequency distribution of sources in Agricultural and Biological Sciences (log–log).\n\n\n\n\n\n\n\nCode\nplot_subfields(dfs[\"Agricultural and Biological Sciences\"])\n\n\n\n\n\n\n\n\nFigure 6: Subfields of Agricultural and Biological Sciences ranked by number of works.\n\n\n\n\n\n\n\nBiochemistry, Genetics and Molecular Biology\n\nCode\ntotal = dfs[\"Biochemistry, Genetics and Molecular Biology\"][\"Works\"].sum()\nn_sources = len(sources[\"Biochemistry, Genetics and Molecular Biology\"])\nprint(f\"OpenAlex entity: [fields/13](https://openalex.org/fields/13) | {total:,} total works | {n_sources:,} unique journals | Subfields data: [CSV](data/subfields.csv)\")\n\nOpenAlex entity: fields/13 | 19,971,736 total works | 95,131 unique journals | Subfields data: CSV\n\n\nCode\nplot_works_by_year(yearly[\"Biochemistry, Genetics and Molecular Biology\"])\n\n\n\n\n\n\n\n\nFigure 7: Annual distribution of works in Biochemistry, Genetics and Molecular Biology.\n\n\n\n\n\n\nCode\ntable_top_sources(sources[\"Biochemistry, Genetics and Molecular Biology\"])\n\n\n\n\n\n\n\n\n\nRank\nSource\nWorks\n\n\n\n\n1\nPubMed\n743,952\n\n\n2\nFigshare\n116,315\n\n\n3\nJournal of Biological Chemistry\n115,980\n\n\n4\nElsevier eBooks\n71,437\n\n\n5\nCancer Research\n68,226\n\n\n6\nProceedings of the National Academy of Sciences\n64,967\n\n\n7\nFaculty Opinions – Post-Publication Peer Review of the Biomedical Literature\n64,646\n\n\n8\nPLoS ONE\n63,245\n\n\n9\nZenodo (CERN European Organization for Nuclear Research)\n50,398\n\n\n10\nBiochemical and Biophysical Research Communications\n50,207\n\n\n11\nNature\n49,111\n\n\n12\nChemInform\n46,221\n\n\n13\nScientific Reports\n44,618\n\n\n14\nBiophysical Journal\n44,257\n\n\n15\nThe FASEB Journal\n44,039\n\n\n16\nHAL (Le Centre pour la Communication Scientifique Directe)\n43,533\n\n\n17\nNucleic Acids Research\n42,310\n\n\n18\nBiochemistry\n41,454\n\n\n19\nMedical Entomology and Zoology\n40,922\n\n\n20\nHarvard Dataverse\n37,587\n\n\n\n\n\nCode\nplot_source_rank_freq(sources[\"Biochemistry, Genetics and Molecular Biology\"])\n\n\n\n\n\n\n\n\nFigure 8: Rank–frequency distribution of sources in Biochemistry, Genetics and Molecular Biology (log–log).\n\n\n\n\n\n\n\nCode\nplot_subfields(dfs[\"Biochemistry, Genetics and Molecular Biology\"])\n\n\n\n\n\n\n\n\nFigure 9: Subfields of Biochemistry, Genetics and Molecular Biology ranked by number of works.\n\n\n\n\n\n\n\nEconomics, Econometrics and Finance\n\nCode\ntotal = dfs[\"Economics, Econometrics and Finance\"][\"Works\"].sum()\nn_sources = len(sources[\"Economics, Econometrics and Finance\"])\nprint(f\"OpenAlex entity: [fields/20](https://openalex.org/fields/20) | {total:,} total works | {n_sources:,} unique journals | Subfields data: [CSV](data/subfields.csv)\")\n\nOpenAlex entity: fields/20 | 10,569,794 total works | 121,718 unique journals | Subfields data: CSV\n\n\nCode\nplot_works_by_year(yearly[\"Economics, Econometrics and Finance\"])\n\n\n\n\n\n\n\n\nFigure 10: Annual distribution of works in Economics, Econometrics and Finance.\n\n\n\n\n\n\nCode\ntable_top_sources(sources[\"Economics, Econometrics and Finance\"])\n\n\n\n\n\n\n\n\n\nRank\nSource\nWorks\n\n\n\n\n1\nSSRN Electronic Journal\n272,734\n\n\n2\nRePEc: Research Papers in Economics\n261,611\n\n\n3\nPubMed\n115,204\n\n\n4\nColumbia Academic Commons (Columbia University)\n65,007\n\n\n5\nDialnet (Universidad de la Rioja)\n50,769\n\n\n6\nMedical Entomology and Zoology\n43,519\n\n\n7\nSHILAP Revista de lepidopterología\n33,454\n\n\n8\narXiv (Cornell University)\n32,812\n\n\n9\nCambridge University Press eBooks\n32,032\n\n\n10\nEconstor (Econstor)\n30,335\n\n\n11\nPalgrave Macmillan UK eBooks\n29,734\n\n\n12\nZenodo (CERN European Organization for Nuclear Research)\n29,369\n\n\n13\nEdward Elgar Publishing eBooks\n24,269\n\n\n14\nHAL (Le Centre pour la Communication Scientifique Directe)\n23,689\n\n\n15\nOxford University Press eBooks\n21,903\n\n\n16\nHarvard Dataverse\n21,148\n\n\n17\nUniversity of Zagreb University Computing Centre (SRCE)\n20,876\n\n\n18\nValue in Health\n18,861\n\n\n19\nData Archiving and Networked Services (DANS)\n16,773\n\n\n20\nLA Referencia (Red Federada de Repositorios Institucionales de Publicaciones Científicas)\n16,199\n\n\n\n\n\nCode\nplot_source_rank_freq(sources[\"Economics, Econometrics and Finance\"])\n\n\n\n\n\n\n\n\nFigure 11: Rank–frequency distribution of sources in Economics, Econometrics and Finance (log–log).\n\n\n\n\n\n\n\nCode\nplot_subfields(dfs[\"Economics, Econometrics and Finance\"])\n\n\n\n\n\n\n\n\nFigure 12: Subfields of Economics, Econometrics and Finance ranked by number of works."
  },
  {
    "objectID": "api-reference.html",
    "href": "api-reference.html",
    "title": "API Quick Reference",
    "section": "",
    "text": "Base URL: https://api.openalex.org | Auth: free API key (get one here) passed as ?api_key=YOUR_KEY | Rate limits: 100,000 credits/day, max 100 req/s"
  },
  {
    "objectID": "api-reference.html#entities",
    "href": "api-reference.html#entities",
    "title": "API Quick Reference",
    "section": "Entities",
    "text": "Entities\n\n\n\nEntity\nCount\nCanonical ID\nEndpoint\n\n\n\n\nWorks\n240 M+\nDOI\n/works\n\n\nAuthors\n—\nORCID\n/authors\n\n\nSources\n249 K\nISSN-L\n/sources\n\n\nInstitutions\n109 K\nROR ID\n/institutions\n\n\nTopics\n~4,500\n—\n/topics\n\n\nPublishers\n~10 K\nWikidata ID\n/publishers\n\n\nFunders\n~32 K\n—\n/funders"
  },
  {
    "objectID": "api-reference.html#key-operations",
    "href": "api-reference.html#key-operations",
    "title": "API Quick Reference",
    "section": "Key operations",
    "text": "Key operations\n\nGet a single entity\nGET /works/W2741809807\nGET /works/https://doi.org/10.7717/peerj.4375\nGET /authors/https://orcid.org/0000-0003-1613-5981\nAccepts OpenAlex IDs, DOIs, ORCIDs, ROR IDs, ISSN-Ls, and Wikidata IDs. Costs 0 credits.\n\n\nList entities (paginated)\nGET /works?per-page=50&page=2\nDefault 25/page, max 200. Basic paging supports up to 10,000 results. For larger sets use cursor paging: start with ?cursor=* and follow next_cursor.\n\n\nFilter\nGET /works?filter=publication_year:2024,cited_by_count:&gt;100,open_access.is_oa:true\n\n\n\nOperator\nSyntax\nExample\n\n\n\n\nAND\ncomma\nfield1:val1,field2:val2\n\n\nOR\npipe\ntype:article\\|review\n\n\nNOT\n!\ncountry_code:!us\n\n\nInequality\n&lt; / &gt;\ncited_by_count:&gt;50\n\n\nDate range\nfrom_ / to_\nfrom_publication_date:2020-01-01\n\n\n\n\n\nSearch\nGET /works?search=machine+learning\nSearches titles, abstracts, and fulltext. Supports AND, OR, NOT, exact phrases in quotes, and .no_stem mode. Results ranked by relevance_score.\n\n\nSort\nGET /works?sort=cited_by_count:desc\nSort fields: display_name, cited_by_count, works_count, publication_date, relevance_score (search only).\n\n\nGroup by\nGET /works?group_by=type\nReturns faceted counts instead of individual results.\n\n\nSelect fields\nGET /works?select=id,doi,display_name,cited_by_count\nReduces the response to only the requested root-level fields.\n\n\nSemantic search\nGET /find/works?query=effects+of+climate+change+on+crop+yields\nAI-powered similarity search across ~217 M works using vector embeddings. Returns results with similarity scores (0–1). Supports POST for queries up to 10,000 characters."
  },
  {
    "objectID": "api-reference.html#credit-costs",
    "href": "api-reference.html#credit-costs",
    "title": "API Quick Reference",
    "section": "Credit costs",
    "text": "Credit costs\n\n\n\nOperation\nCredits\n\n\n\n\nSingle entity lookup\n0\n\n\nList query\n1\n\n\nSearch\n10\n\n\nSemantic search (/find/works)\n1,000\n\n\nContent download (PDF/XML)\n100"
  },
  {
    "objectID": "api-reference.html#sample-record",
    "href": "api-reference.html#sample-record",
    "title": "API Quick Reference",
    "section": "Sample record",
    "text": "Sample record\nA single work fetched via GET /works/W2741809807:\n{\n  \"id\": \"https://openalex.org/W2741809807\",\n  \"doi\": \"https://doi.org/10.7717/peerj.4375\",\n  \"title\": \"The state of OA: a large-scale analysis of the prevalence and impact of Open Access articles\",\n  \"publication_year\": 2018,\n  \"type\": \"book-chapter\",\n  \"open_access\": {\n    \"is_oa\": true,\n    \"oa_status\": \"gold\",\n    \"oa_url\": \"https://doi.org/10.7717/peerj.4375\"\n  },\n  \"cited_by_count\": 1149,\n  \"primary_topic\": {\n    \"id\": \"https://openalex.org/T10102\",\n    \"display_name\": \"scientometrics and bibliometrics research\",\n    \"subfield\": { \"display_name\": \"Statistics, Probability and Uncertainty\" },\n    \"field\": { \"display_name\": \"Decision Sciences\" },\n    \"domain\": { \"display_name\": \"Social Sciences\" }\n  }\n}"
  },
  {
    "objectID": "api-reference.html#further-reading",
    "href": "api-reference.html#further-reading",
    "title": "API Quick Reference",
    "section": "Further reading",
    "text": "Further reading\n\nOfficial API docs\nData snapshot — free monthly database download"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OpenAlex API Examples",
    "section": "",
    "text": "OpenAlex is a free, open catalog of the world’s scholarly research — over 240 million works (journal articles, books, datasets, theses), updated daily. This repository collects Python examples that show how to query and visualise data from the OpenAlex REST API."
  },
  {
    "objectID": "index.html#whats-here",
    "href": "index.html#whats-here",
    "title": "OpenAlex API Examples",
    "section": "What’s here",
    "text": "What’s here\n\n\n\nAPI Reference\nEntities, filters, search, pagination, and credit costs — everything you need to start querying.\n\n\n\n\nTopic Search\nHow OpenAlex classifies works into a four-level taxonomy (Domain → Field → Subfield → Topic), plus a CLI tool.\n\n\n\n\nExample Notebook\nQuerying the /subfields endpoint and charting work counts across four academic fields."
  },
  {
    "objectID": "index.html#sample-record",
    "href": "index.html#sample-record",
    "title": "OpenAlex API Examples",
    "section": "Sample record",
    "text": "Sample record\nEvery work in OpenAlex is a richly structured JSON object with 50 top-level fields. At its core you get identity information (OpenAlex ID, DOI, title) and publication metadata (year, date, language, document type). The primary location block tells you where the work was published — journal name, ISSN, license, and version — while the open access block summarises whether it is freely available and through which route (gold, green, hybrid, bronze, or closed).\nAuthorship data links each contributor to their ORCID, affiliated institutions (with ROR IDs), and country codes, and flags the corresponding author. Aggregate counts for distinct countries and institutions are provided alongside. Article processing charges (list price and amount paid) are recorded when available.\nCitation metrics include the raw count, field-weighted citation impact (FWCI), normalised percentile rankings, and a year-by-year breakdown. Bibliographic details cover volume, issue, and page numbers, plus boolean flags for retraction and paratext status.\nEach work is classified through a four-level topic hierarchy — domain, field, subfield, and topic — with confidence scores. The primary (best-matching) topic and additional high-scoring topics are provided separately. Keywords offer machine-generated terms with relevance scores; the legacy concepts field (Wikidata-linked, hierarchical) is deprecated but still present. MeSH terms and UN Sustainable Development Goals appear when applicable.\nThe locations array lists every place the work appears (publisher site, PubMed, institutional repositories, etc.), and best_oa_location picks the best open-access copy. Funding and awards are captured when metadata is available. References (outgoing citations) and related works (algorithmically similar) are given as lists of OpenAlex IDs. The abstract is stored as an inverted index (word → position list) to support full-text search without redistributing copyrighted text. Finally, record timestamps track when the entry was created and last updated.\nBelow is the full structure for GET /works/W2741809807, with arrays trimmed to the first element:\n{\n  // ── Identity ──────────────────────────────────────────────────\n  \"id\": \"https://openalex.org/W2741809807\",       // OpenAlex URI\n  \"doi\": \"https://doi.org/10.7717/peerj.4375\",    // DOI as URL\n  \"title\": \"The state of OA: ...\",                 // full title\n  \"display_name\": \"The state of OA: ...\",          // same as title\n  \"ids\": {                                         // cross-referenced IDs\n    \"openalex\": \"https://openalex.org/W2741809807\",\n    \"doi\": \"https://doi.org/10.7717/peerj.4375\",\n    \"mag\": \"2741809807\",\n    \"pmid\": \"https://pubmed.ncbi.nlm.nih.gov/29456894\"\n  },\n\n  // ── Publication metadata ──────────────────────────────────────\n  \"publication_year\": 2018,\n  \"publication_date\": \"2018-02-13\",\n  \"language\": \"en\",                                // ISO 639-1 code\n  \"type\": \"book-chapter\",                          // Crossref type\n  \"indexed_in\": [\"crossref\", \"doaj\", \"pubmed\"],    // indexing databases\n\n  // ── Primary location (where the work is published) ────────────\n  \"primary_location\": {\n    \"is_oa\": true,\n    \"landing_page_url\": \"https://doi.org/10.7717/peerj.4375\",\n    \"pdf_url\": null,\n    \"source\": {\n      \"id\": \"https://openalex.org/S1983995261\",\n      \"display_name\": \"PeerJ\",\n      \"issn_l\": \"2167-8359\",\n      \"is_oa\": true,\n      \"is_in_doaj\": true,\n      \"type\": \"journal\"\n    },\n    \"license\": \"cc-by\",\n    \"version\": \"publishedVersion\"\n  },\n\n  // ── Open Access status ────────────────────────────────────────\n  \"open_access\": {\n    \"is_oa\": true,\n    \"oa_status\": \"gold\",                           // gold|green|hybrid|bronze|closed\n    \"oa_url\": \"https://doi.org/10.7717/peerj.4375\",\n    \"any_repository_has_fulltext\": true\n  },\n\n  // ── Authors & affiliations (9 authors, first shown) ───────────\n  \"authorships\": [\n    {\n      \"author_position\": \"first\",                  // first|middle|last\n      \"author\": {\n        \"id\": \"https://openalex.org/A5048491430\",\n        \"display_name\": \"Heather Piwowar\",\n        \"orcid\": \"https://orcid.org/0000-0003-1613-5981\"\n      },\n      \"institutions\": [\n        {\n          \"id\": \"https://openalex.org/I4210166736\",\n          \"display_name\": \"Impact Technology Development (United States)\",\n          \"ror\": \"https://ror.org/05ppvf150\",\n          \"country_code\": \"US\",\n          \"type\": \"company\"\n        }\n      ],\n      \"countries\": [\"US\"],\n      \"is_corresponding\": true\n    }\n    // ... 8 more authors\n  ],\n\n  // ── Aggregate author/institution stats ────────────────────────\n  \"institutions\": [],                              // deprecated; use authorships\n  \"countries_distinct_count\": 2,\n  \"institutions_distinct_count\": 9,\n  \"corresponding_author_ids\": [\"https://openalex.org/A5048491430\"],\n  \"corresponding_institution_ids\": [\"https://openalex.org/I4210166736\"],\n\n  // ── Article processing charges ────────────────────────────────\n  \"apc_list\": { \"value\": 1395, \"currency\": \"USD\", \"value_usd\": 1395 },\n  \"apc_paid\": { \"value\": 1395, \"currency\": \"USD\", \"value_usd\": 1395 },\n\n  // ── Citation metrics ──────────────────────────────────────────\n  \"fwci\": 504.41,                                  // field-weighted citation impact\n  \"cited_by_count\": 1149,\n  \"citation_normalized_percentile\": {\n    \"value\": 1.0,\n    \"is_in_top_1_percent\": true,\n    \"is_in_top_10_percent\": true\n  },\n  \"cited_by_percentile_year\": { \"min\": 99, \"max\": 100 },\n  \"counts_by_year\": [                              // annual citation breakdown\n    { \"year\": 2026, \"cited_by_count\": 17 },\n    { \"year\": 2025, \"cited_by_count\": 133 }\n    // ... more years\n  ],\n\n  // ── Bibliographic details ─────────────────────────────────────\n  \"biblio\": {\n    \"volume\": \"6\",\n    \"issue\": null,\n    \"first_page\": \"e4375\",\n    \"last_page\": \"e4375\"\n  },\n  \"has_fulltext\": false,\n  \"is_retracted\": false,\n  \"is_paratext\": false,\n  \"is_xpac\": false,\n\n  // ── Topic classification (4-level hierarchy) ──────────────────\n  \"primary_topic\": {                               // single best-matching topic\n    \"id\": \"https://openalex.org/T10102\",\n    \"display_name\": \"scientometrics and bibliometrics research\",\n    \"score\": 0.9969,                               // confidence 0–1\n    \"subfield\": { \"display_name\": \"Statistics, Probability and Uncertainty\" },\n    \"field\":    { \"display_name\": \"Decision Sciences\" },\n    \"domain\":   { \"display_name\": \"Social Sciences\" }\n  },\n  \"topics\": [                                      // additional high-scoring topics\n    { \"id\": \"...\", \"display_name\": \"...\", \"score\": 0.98 }\n    // ...\n  ],\n\n  // ── Keywords, concepts & subject tags ─────────────────────────\n  \"keywords\": [\n    { \"id\": \"https://openalex.org/keywords/citation\", \"display_name\": \"Citation\", \"score\": 0.69 }\n    // ... more keywords\n  ],\n  \"concepts\": [                                    // legacy (deprecated); use topics\n    { \"id\": \"...\", \"display_name\": \"Citation\", \"level\": 2, \"score\": 0.69 }\n    // ...\n  ],\n  \"mesh\": [],                                      // MeSH terms (biomedical works)\n  \"sustainable_development_goals\": [],             // UN SDG tags\n\n  // ── All locations where the work appears ──────────────────────\n  \"locations_count\": 6,\n  \"locations\": [                                   // publisher, repositories, etc.\n    { \"is_oa\": true, \"source\": { \"display_name\": \"PeerJ\" }, \"version\": \"publishedVersion\" }\n    // ... 5 more locations\n  ],\n  \"best_oa_location\": { \"...\" : \"same structure as primary_location\" },\n\n  // ── Funding & awards ──────────────────────────────────────────\n  \"awards\": [],\n  \"funders\": [],\n\n  // ── Content availability ──────────────────────────────────────\n  \"has_content\": { \"grobid_xml\": false, \"pdf\": false },\n  \"content_urls\": null,\n\n  // ── References & related works ────────────────────────────────\n  \"referenced_works_count\": 54,\n  \"referenced_works\": [                            // outgoing citations\n    \"https://openalex.org/W1560783210\"\n    // ... 53 more\n  ],\n  \"related_works\": [                               // algorithmically related\n    \"https://openalex.org/W2294604317\"\n    // ... more\n  ],\n\n  // ── Abstract (stored as inverted index) ───────────────────────\n  \"abstract_inverted_index\": {                     // word → list of positions\n    \"Despite\": [0], \"growing\": [1], \"interest\": [2]\n    // ...\n  },\n\n  // ── Record timestamps ─────────────────────────────────────────\n  \"updated_date\": \"2026-02-16T07:36:33.822630\",\n  \"created_date\": \"2025-10-10T00:00:00\"\n}\n\n\n\n\n\n\nNote\n\n\n\nOn February 16 2026, I gathered a data dump of OpenAlex, which is available via a bulk download:\naws s3 sync \"s3://openalex\" \"openalex-snapshot\" --no-sign-request"
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "OpenAlex API Examples",
    "section": "Quick start",
    "text": "Quick start\n# clone the repo\ngit clone https://github.com/&lt;you&gt;/openalex.git\ncd openalex\n\n# set up a virtual environment\npython -m venv .venv && source .venv/bin/activate\npip install httpx pandas matplotlib requests\n\n# run the CLI tool\npython topicSearch/get_subfields.py --list\npython topicSearch/get_subfields.py \"Computer Science\""
  },
  {
    "objectID": "index.html#links",
    "href": "index.html#links",
    "title": "OpenAlex API Examples",
    "section": "Links",
    "text": "Links\n\nOpenAlex — the platform\nOfficial API docs — full reference\nGitHub repo — source code"
  },
  {
    "objectID": "topic-search.html",
    "href": "topic-search.html",
    "title": "Topic Search",
    "section": "",
    "text": "OpenAlex classifies every work into a four-level taxonomy, from broadest to most specific:\n\n\n\nLevel\nCount\nExample\n\n\n\n\nDomain\n4\nPhysical Sciences\n\n\nField\n26\nPhysics and Astronomy\n\n\nSubfield\n200\nNuclear and High Energy Physics\n\n\nTopic\n4,516\nMagnetic confinement fusion research\n\n\n\n\n\n\n\n\nDomain\nTopics\n\n\n\n\nPhysical Sciences\n1,571\n\n\nSocial Sciences\n1,487\n\n\nHealth Sciences\n844\n\n\nLife Sciences\n614"
  },
  {
    "objectID": "topic-search.html#topic-hierarchy",
    "href": "topic-search.html#topic-hierarchy",
    "title": "Topic Search",
    "section": "",
    "text": "OpenAlex classifies every work into a four-level taxonomy, from broadest to most specific:\n\n\n\nLevel\nCount\nExample\n\n\n\n\nDomain\n4\nPhysical Sciences\n\n\nField\n26\nPhysics and Astronomy\n\n\nSubfield\n200\nNuclear and High Energy Physics\n\n\nTopic\n4,516\nMagnetic confinement fusion research\n\n\n\n\n\n\n\n\nDomain\nTopics\n\n\n\n\nPhysical Sciences\n1,571\n\n\nSocial Sciences\n1,487\n\n\nHealth Sciences\n844\n\n\nLife Sciences\n614"
  },
  {
    "objectID": "topic-search.html#how-topics-are-assigned",
    "href": "topic-search.html#how-topics-are-assigned",
    "title": "Topic Search",
    "section": "How topics are assigned",
    "text": "How topics are assigned\nOpenAlex uses an automated classifier that scores every work across all ~4,500 topics based on the work’s title, abstract, source (journal) name, and citations.\n\nprimary_topic — the single highest-scoring topic, including its score (0–1) and full hierarchy (subfield → field → domain)\ntopics — a list of additional highly ranked topics, each with their own score and hierarchy\n\n{\n  \"primary_topic\": {\n    \"id\": \"https://openalex.org/T10346\",\n    \"display_name\": \"Magnetic confinement fusion research\",\n    \"score\": 0.9991,\n    \"subfield\": { \"display_name\": \"Nuclear and High Energy Physics\" },\n    \"field\":    { \"display_name\": \"Physics and Astronomy\" },\n    \"domain\":   { \"display_name\": \"Physical Sciences\" }\n  }\n}"
  },
  {
    "objectID": "topic-search.html#topic-object-structure",
    "href": "topic-search.html#topic-object-structure",
    "title": "Topic Search",
    "section": "Topic object structure",
    "text": "Topic object structure\nEach topic entity (/topics/{id}) contains:\n\n\n\nField\nDescription\n\n\n\n\nid\nOpenAlex URI (e.g. https://openalex.org/T10346)\n\n\ndisplay_name\nEnglish-language label\n\n\ndescription\nAI-generated summary of the paper cluster\n\n\nkeywords\nAI-generated representative terms\n\n\nids\nExternal identifiers (OpenAlex, Wikipedia)\n\n\nsubfield\nParent subfield (id + display_name)\n\n\nfield\nParent field\n\n\ndomain\nParent domain\n\n\nsiblings\nOther topics in the same subfield\n\n\nworks_count\nNumber of works tagged with this topic\n\n\ncited_by_count\nTotal citations across tagged works\n\n\nworks_api_url\nAPI URL to retrieve works for this topic"
  },
  {
    "objectID": "topic-search.html#useful-api-queries",
    "href": "topic-search.html#useful-api-queries",
    "title": "Topic Search",
    "section": "Useful API queries",
    "text": "Useful API queries\n# List all topics\ncurl \"https://api.openalex.org/topics\"\n\n# Search topics by name\ncurl \"https://api.openalex.org/topics?search=machine+learning\"\n\n# Get topics grouped by domain\ncurl \"https://api.openalex.org/topics?group_by=domain.id\"\n\n# Filter works by a specific topic\ncurl \"https://api.openalex.org/works?filter=topics.id:T10346\"\n\n# Filter works by primary topic only\ncurl \"https://api.openalex.org/works?filter=primary_topic.id:T10346\"\n\n# Filter works by subfield\ncurl \"https://api.openalex.org/works?filter=primary_topic.subfield.id:3106\""
  },
  {
    "objectID": "topic-search.html#cli-tool-get_subfields.py",
    "href": "topic-search.html#cli-tool-get_subfields.py",
    "title": "Topic Search",
    "section": "CLI tool: get_subfields.py",
    "text": "CLI tool: get_subfields.py\nThe repository includes a command-line utility for querying subfields interactively.\n\nUsage\n# List all 26 fields\npython topicSearch/get_subfields.py --list\n\n# Look up by name\npython topicSearch/get_subfields.py \"Computer Science\"\n\n# Look up by numeric ID\npython topicSearch/get_subfields.py 17\n\n\nSource\n\n\ntopicSearch/get_subfields.py\n\n\"\"\"Retrieve the subfields associated with an OpenAlex field.\n\nUsage:\n    python get_subfields.py \"Computer Science\"\n    python get_subfields.py 17              # field ID number\n    python get_subfields.py --list          # list all fields\n\"\"\"\n\nimport argparse\nimport sys\nimport requests\n\nBASE_URL = \"https://api.openalex.org\"\n\n\ndef list_fields():\n    \"\"\"Print all available fields.\"\"\"\n    resp = requests.get(f\"{BASE_URL}/fields\", params={\"per_page\": 50})\n    resp.raise_for_status()\n    fields = resp.json()[\"results\"]\n    print(f\"{'ID':&lt;6} {'Field':&lt;45} {'Domain'}\")\n    print(\"-\" * 80)\n    for f in sorted(fields, key=lambda x: x[\"display_name\"]):\n        fid = f[\"id\"].split(\"/\")[-1]\n        print(f\"{fid:&lt;6} {f['display_name']:&lt;45} {f['domain']['display_name']}\")\n\n\ndef resolve_field(query):\n    \"\"\"Resolve a field by numeric ID or search string. Returns the field object.\"\"\"\n    if query.isdigit():\n        resp = requests.get(f\"{BASE_URL}/fields/{query}\")\n        if resp.status_code == 404:\n            sys.exit(f\"No field found with ID {query}\")\n        resp.raise_for_status()\n        return resp.json()\n\n    resp = requests.get(f\"{BASE_URL}/fields\", params={\"search\": query})\n    resp.raise_for_status()\n    results = resp.json()[\"results\"]\n    if not results:\n        sys.exit(f\"No field found matching '{query}'\")\n    return results[0]\n\n\ndef get_subfields(field):\n    \"\"\"Fetch subfields for a field, including topic counts.\"\"\"\n    field_id = field[\"id\"].split(\"/\")[-1]\n    resp = requests.get(\n        f\"{BASE_URL}/subfields\",\n        params={\"filter\": f\"field.id:{field_id}\", \"per_page\": 50},\n    )\n    resp.raise_for_status()\n    return resp.json()[\"results\"]\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Get subfields for an OpenAlex field\")\n    parser.add_argument(\"field\", nargs=\"?\", help=\"Field name (search) or numeric ID\")\n    parser.add_argument(\"--list\", action=\"store_true\", help=\"List all available fields\")\n    args = parser.parse_args()\n\n    if args.list:\n        list_fields()\n        return\n\n    if not args.field:\n        parser.print_help()\n        sys.exit(1)\n\n    field = resolve_field(args.field)\n    print(f\"\\nField: {field['display_name']}\")\n    print(f\"Domain: {field['domain']['display_name']}\\n\")\n\n    subfields = get_subfields(field)\n    print(f\"{'ID':&lt;6} {'Subfield':&lt;50} {'Topics':&gt;8}  {'Works':&gt;12}\")\n    print(\"-\" * 80)\n    for sf in sorted(subfields, key=lambda x: x[\"works_count\"], reverse=True):\n        sfid = sf[\"id\"].split(\"/\")[-1]\n        n_topics = len(sf.get(\"topics\", []))\n        print(f\"{sfid:&lt;6} {sf['display_name']:&lt;50} {n_topics:&gt;8}  {sf['works_count']:&gt;12,}\")\n\n    print(f\"\\nTotal: {len(subfields)} subfields\")\n\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "topic-search.html#references",
    "href": "topic-search.html#references",
    "title": "Topic Search",
    "section": "References",
    "text": "References\n\nOpenAlex Topics docs\nTopic object reference\nPaper: OpenAlex: End-to-End Process for Topic Classification"
  }
]